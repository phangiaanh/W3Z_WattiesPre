# @package _global_

defaults:
  - model/backbone
  - model/cls_header
  - model/classifier
  - model/regressors
  - model/router
  - model/smal
  - data/dataset
  - training/optimizer
  - training/scheduler
  - training/loss_weights
  - evaluation/metrics

# Model configuration
model:
  image_size: 256
  num_categories: 5

# HuggingFace configuration
huggingface:
  repo_id: WatermelonAnh/WattiesMammals  # HuggingFace repository ID
  token: null  # Set via HUGGINGFACE_TOKEN env var or here
  cache_dir: null  # Cache directory for downloaded files

# Training configuration
training:
  batch_size: 16
  num_epochs: 100
  num_workers: 4
  pin_memory: true

# Paths
paths:
  output_dir: /content/drive/MyDrive/WattiesPre/outputs
  checkpoint_dir: /content/drive/MyDrive/WattiesPre/checkpoints
  log_dir: /content/drive/MyDrive/WattiesPre/logs

# Checkpoint configuration
checkpoint:
  save_checkpoint_every: 10  # Save checkpoint every N epochs
  save_best_model: true  # Whether to save best model
  resume_from: null  # Path to checkpoint to resume from (optional)
  best_metric: val_loss  # Metric to track for best model ('val_loss' or 'val_acc')

# Logging configuration
logging:
  log_format: csv  # 'csv' or 'json'
  log_iteration_every: 1  # Log every N iterations (1 = log all)
  log_gradient_norm: true  # Whether to compute and log gradient norms
  log_learning_rate: true  # Whether to log learning rate
  log_file_prefix: training  # Prefix for log files

# General
seed: 42
device: cuda

